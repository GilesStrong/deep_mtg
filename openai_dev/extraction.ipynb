{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"The color of the person's hair if known\"\n",
    "    )\n",
    "    height_in_meters: Optional[float] = Field(\n",
    "        default=None, description=\"Height measured in meters\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Information about a person.',\n",
       " 'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'The name of the person',\n",
       "   'title': 'Name'},\n",
       "  'hair_color': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': \"The color of the person's hair if known\",\n",
       "   'title': 'Hair Color'},\n",
       "  'height_in_meters': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'Height measured in meters',\n",
       "   'title': 'Height In Meters'}},\n",
       " 'title': 'Person',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Person.model_json_schema()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'string'}, {'type': 'null'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Person.model_json_schema()['properties']['name']['anyOf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22787/832530925.py:1: PydanticDeprecatedSince20: The `parse_raw` method is deprecated; if your data is JSON use `model_validate_json`, otherwise load the data then use `model_validate` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  Person.parse_raw('{\"name\": \"Alice\", \"height_in_meters\": 1.7}')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Person(name='Alice', hair_color=None, height_in_meters=1.7)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Person.parse_raw('{\"name\": \"Alice\", \"height_in_meters\": 1.7}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Type\n",
    "import json\n",
    "from pydantic import TypeAdapter\n",
    "\n",
    "class LLM():\n",
    "    def __init__(self, output_model:Type[BaseModel]):\n",
    "        self.client = OpenAI()\n",
    "        self.output_model = output_model\n",
    "        system_prompt = \"Given the user-submitted text, identify the following information.\"\n",
    "        \n",
    "        schema = self.output_model.model_json_schema()\n",
    "        system_prompt += f\"\\nThe output json will contain {schema['description']}. Extract the information into JSON format:\"\n",
    "        system_prompt += '\\n\\n{'\n",
    "        for field in schema['properties'].keys():\n",
    "            system_prompt += f\"\\n{field}: {schema['properties'][field]['description']}  # {schema['properties'][field]['description']}\"\n",
    "        system_prompt += '\\n}'\n",
    "        \n",
    "        self.system_prompt = {\"role\": \"system\", \"content\": system_prompt}\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "        return self.invoke(*args, **kwds)\n",
    "    \n",
    "    def process(self, response:str) -> BaseModel|str:\n",
    "        try:\n",
    "            return TypeAdapter(self.output_model).validate_json(response)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return response\n",
    "\n",
    "    def invoke(self, text:str) -> BaseModel|str:\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                self.system_prompt,\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        return self.process(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Alice', hair_color=None, height_in_meters=1.7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "TypeAdapter(Person).validate_json('{\"name\": \"Alice\", \"height_in_meters\": 1.7}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the user-submitted text, identify the following information.\n",
      "The output json will contain Information about a person.. Extract the information into JSON format:\n",
      "\n",
      "{\n",
      "name: The name of the person  # The name of the person\n",
      "hair_color: The color of the person's hair if known  # The color of the person's hair if known\n",
      "height_in_meters: Height measured in meters  # Height measured in meters\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(llm.system_prompt['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"The person's name is John Doe, they have brown hair, and are 1.8 meters tall.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Alan Smith', hair_color='blond', height_in_meters=1.8288)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Alan Smith is 6 feet tall and has blond hair.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='John Doe', hair_color='brown', height_in_meters=1.8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
