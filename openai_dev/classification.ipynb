{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class LLM():\n",
    "    def __init__(self, system_message):\n",
    "        self.client = OpenAI()\n",
    "        self.system_prompt = {\"role\": \"system\", \"content\": system_message}\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "        return self.invoke(*args, **kwds)\n",
    "\n",
    "    def invoke(self, text):\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                self.system_prompt,\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ]\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\"Given the user-submitted text, identify the language, sentiment, and aggressiveness. Output the results in json format with the following fields ['language', 'sentiment', 'aggressiveness'].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(\"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"language\": \"Spanish\",\\n  \"sentiment\": \"positive\",\\n  \"aggressiveness\": \"non-aggressive\"\\n}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'language': 'Spanish',\n",
       " 'sentiment': 'positive',\n",
       " 'aggressiveness': 'non-aggressive'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    \"\"\"Text classification response\"\"\"\n",
    "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
    "    aggressiveness: int = Field(\n",
    "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
    "    )\n",
    "    language: str = Field(description=\"The language the text is written in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"annotation=str required=True description='The sentiment of the text'\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{Classification.model_fields['sentiment']}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\n",
    "for key in Classification.model_fields.keys():\n",
    "    field = Classification.model_fields[key]\n",
    "    system_prompt += f\"\\n{key}: {field.annotation}  # {field.description}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentiment: <class 'str'>  # The sentiment of the text\n",
      "aggressiveness: <class 'int'>  # How aggressive the text is on a scale from 1 to 10\n",
      "language: <class 'str'>  # The language the text is written in\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Type\n",
    "from pydantic import TypeAdapter\n",
    "\n",
    "class LLM():\n",
    "    def __init__(self, output_model:Type[BaseModel]):\n",
    "        self.client = OpenAI()\n",
    "        self.output_model = output_model\n",
    "        system_prompt = \"Given the user-submitted text, identify the following information.\"\n",
    "        \n",
    "        schema = self.output_model.model_json_schema()\n",
    "        system_prompt += f\"\\nThe output json will contain {schema['description']}. Extract the information into JSON format:\"\n",
    "        system_prompt += '\\n\\n{'\n",
    "        for field in schema['properties'].keys():\n",
    "            system_prompt += f\"\\n{field}: {schema['properties'][field]['description']}  # {schema['properties'][field]['description']}\"\n",
    "        system_prompt += '\\n}'\n",
    "        \n",
    "        self.system_prompt = {\"role\": \"system\", \"content\": system_prompt}\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "        return self.invoke(*args, **kwds)\n",
    "    \n",
    "    def process(self, response:str) -> BaseModel|str:\n",
    "        try:\n",
    "            return TypeAdapter(self.output_model).validate_json(response)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return response\n",
    "\n",
    "    def invoke(self, text):\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                self.system_prompt,\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        return self.process(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Text classification response',\n",
       " 'properties': {'sentiment': {'description': 'The sentiment of the text',\n",
       "   'title': 'Sentiment',\n",
       "   'type': 'string'},\n",
       "  'aggressiveness': {'description': 'How aggressive the text is on a scale from 1 to 10',\n",
       "   'title': 'Aggressiveness',\n",
       "   'type': 'integer'},\n",
       "  'language': {'description': 'The language the text is written in',\n",
       "   'title': 'Language',\n",
       "   'type': 'string'}},\n",
       " 'required': ['sentiment', 'aggressiveness', 'language'],\n",
       " 'title': 'Classification',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Given the user-submitted text, identify the following information, and extract it into JSON format:\n",
      "{\n",
      "        \n",
      "sentiment: <class 'str'>  # The sentiment of the text\n",
      "aggressiveness: <class 'int'>  # How aggressive the text is on a scale from 1 to 10\n",
      "language: <class 'str'>  # The language the text is written in\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(llm.system_prompt['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Type\n",
    "from pydantic import TypeAdapter\n",
    "\n",
    "class LLM():\n",
    "    def __init__(self, output_model:Type[BaseModel]):\n",
    "        self.client = OpenAI()\n",
    "        self.output_model = output_model\n",
    "        system_prompt = \"Given the user-submitted text, identify the required information.\"\n",
    "        self.system_prompt = {\"role\": \"system\", \"content\": system_prompt}\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "        return self.invoke(*args, **kwds)\n",
    "    \n",
    "    def process(self, response:str) -> BaseModel|str:\n",
    "        try:\n",
    "            return TypeAdapter(self.output_model).validate_json(response)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return response\n",
    "\n",
    "    def invoke(self, text):\n",
    "        completion = self.client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                self.system_prompt,\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            response_format=self.output_model\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        return self.process(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = LLM(Classification)\n",
    "llm.invoke(\"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_json = json.loads('{\\n    \"sentiment\": \"positive\",\\n    \"aggressiveness\": 1,\\n    \"language\": \"Spanish\"\\n}')\n",
    "processed_json = {}\n",
    "for key in raw_json.keys():\n",
    "    processed_json[key] = Classification.model_fields[key].annotation(raw_json[key])\n",
    "model = Classification(**processed_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='enojado', aggressiveness=8, language='español')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Estoy muy enojado con vos! Te voy a dar tu merecido!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
