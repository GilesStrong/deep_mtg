{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_text(text:str) -> str:\n",
    "    client = OpenAI()\n",
    "    summary = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Produce a concise summary of the following text.\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [summarise_text(split.page_content) for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The article \"LLM Powered Autonomous Agents\" by Lilian Weng explores the development of autonomous agents using large language models (LLMs) as their central controller. It outlines key system components including planning—where agents decompose tasks and engage in self-reflection; memory—distinguished between short-term and long-term for information retention; and tool use—where agents utilize external APIs for additional resources. The article highlights various proof-of-concept demonstrations like AutoGPT and BabyAGI, emphasizing the potential of LLMs to function as general problem solvers beyond mere content generation.',\n",
       " 'The text discusses the components of a Large Language Model (LLM)-powered autonomous agent system, focusing on planning and self-reflection. Planning involves task decomposition techniques such as Chain of Thought (CoT) and Tree of Thoughts, which break complex tasks into manageable steps and explore multiple reasoning pathways. An external classical planner (LLM+P) can also be employed for long-horizon planning, utilizing Planning Domain Definition Language (PDDL). \\n\\nSelf-reflection enables agents to refine their decisions through trial and error. Techniques like ReAct integrate reasoning with actions, allowing LLM to generate reasoning traces in natural language. Another approach, Reflexion, enhances agents with dynamic memory and a reward model to evaluate performance and correct inefficiencies or mistakes based on heuristic evaluations. Overall, these frameworks aim to improve the efficiency and effectiveness of autonomous agents in complex environments.',\n",
       " 'The text discusses two concepts aimed at improving model performance: Chain of Hindsight (CoH) and Algorithm Distillation (AD). CoH focuses on enhancing model outputs by providing a sequence of past outputs accompanied by human feedback, allowing the model to self-reflect and produce better results through supervised fine-tuning. It employs regularization to prevent overfitting and random masking to tackle shortcutting. Experiments show CoH enables incremental improvement in outputs.\\n\\nOn the other hand, AD is utilized in reinforcement learning by using a history of actions across multiple episodes to create a task-agnostic policy. It aims to distill learning histories from various source policies and trains the model to predict actions that enhance performance based on past experiences. Compared to other methods, AD demonstrates a',\n",
       " 'The text discusses the comparison of different algorithms (AD, ED, source policy, and RL^2) on environments requiring memory and exploration, highlighting the use of binary rewards and training methods like A3C and DQN. It then delves into the concept of memory, explaining its types: sensory memory (brief retention of sensory information), short-term memory (limited capacity for immediate information), and long-term memory (vast storage of information). The article draws parallels between human memory types and data processing components, suggesting mappings such as sensory memory representing raw inputs and long-term memory corresponding to an external vector store accessed during queries. Additionally, it introduces Maximum Inner Product Search (MIPS) as a method to efficiently utilize external memory, mentioning the use of approximate nearest neighbors (ANN) algorithms for optimizing retrieval speed.',\n",
       " 'The text discusses several algorithms used for approximate nearest neighbor search: \\n\\n1. **Locality-Sensitive Hashing (LSH)** maps similar items into the same buckets to reduce search space.\\n2. **ANNOY** utilizes random projection trees to partition the input space and improves search efficiency through iterative querying of closest halves.\\n3. **HNSW** is based on small-world networks, using hierarchical layers to expedite searches from a random top node down to actual data points.\\n4. **FAISS** employs vector quantization and clustering in high-dimensional spaces for efficient search, first coarsely then finely within clusters.\\n5. **ScaNN** innovatively uses anisotropic vector quantization to enhance similarity measurement during searches.\\n\\nThe text also emphasizes the significance of tool use, highlighting how equipping LLMs with external tools can enhance their capabilities.',\n",
       " \"The text discusses MRKL, a neuro-symbolic architecture designed for autonomous agents, which utilizes expert modules and a general-purpose language model (LLM) to process inquiries. It highlights experiments showing that LLMs struggle more with verbal math problems than explicit ones due to difficulties in extracting necessary arguments. Additionally, it mentions TALM and Toolformer, which enhance LLMs' capabilities to use external tool APIs, exemplified by ChatGPT plugins and OpenAI API function calling. HuggingGPT is introduced as a framework that enables ChatGPT to plan tasks and select appropriate models from the HuggingFace platform. The overall system consists of four stages: task planning, model selection, task execution, and logging results, emphasizing the importance of how LLMs utilize external tools and APIs based on user requests and context.\",\n",
       " 'The text discusses the process and challenges of using AI assistants, particularly large language models (LLMs), in task execution and performance evaluation through the benchmark API-Bank. It outlines a structured workflow involving user input, task planning, model selection, and task execution, culminating in response generation. Key challenges highlighted include improving efficiency, dealing with long context windows, and ensuring stability in outputs. API-Bank serves as a framework for evaluating tool-augmented LLMs, assessing their ability to call appropriate APIs, retrieve relevant information, and execute complex tasks that may require multiple API calls. \\n\\nThe document also presents a case study of ChemCrow, an LLM augmented with expert-designed tools for scientific discovery in organic synthesis and drug discovery. Despite similarity in LLM-based assessments between ChemCrow and GPT-4, human evaluators found ChemCrow significantly better in achieving chemically accurate outcomes, suggesting limitations in LLM self-assessment capabilities in expert domains. Overall, it emphasizes that while LLMs are powerful, their effectiveness greatly depends on appropriate tool usage and expert evaluation.',\n",
       " 'The text discusses recent developments in anticancer drug discovery, including selecting a target and synthesizing compounds. Risks associated with illicit drug synthesis and bioweapons were also addressed, with a test set developed for known chemical weapon agents, resulting in a mixed success rate for synthesis requests. Furthermore, the concept of Generative Agents, a simulation involving 25 LLM-powered virtual characters, is explored. These agents utilize long-term memory, reflection mechanisms, and planning to create believable human-like behaviors in a sandbox environment, demonstrating emergent social behaviors such as relationship building and coordination of activities. Lastly, the text mentions AutoGPT, a proof-of-concept demo showcasing autonomous agent capabilities, though it acknowledges certain reliability issues and constraints in its operation.',\n",
       " 'The text outlines a set of commands for various tasks such as searching online, browsing websites, managing GPT agents, file handling, code analysis, and generating content. It highlights resources like internet access and memory management to assist with these tasks. Moreover, it emphasizes the importance of performance evaluation through self-reflection and efficiency, urging the user to optimize task completion while being mindful of costs associated with each command.',\n",
       " '{\\n    \"thoughts\": {\\n        \"text\": \"The task involves creating a Super Mario game in Python with MVC architecture and keyboard control.\",\\n        \"reasoning\": \"Clarifying the details of the game is essential to ensure a comprehensive understanding before coding.\",\\n        \"plan\": \"- Clarify game specifics\\\\n- Define MVC structure\\\\n- Outline keyboard controls\\\\n- Proceed with coding after clarifications\",\\n        \"criticism\": \"I should have asked for assumptions and additional detail sooner to prevent ambiguity.\",\\n        \"speak\": \"I understand we are working on a Super Mario game in Python. I have a few clarifications to ensure we meet your expectations.\"\\n    },\\n    \"command\": {\\n        \"name\": \"clarification\",\\n        \"args\": {\\n            \"question\": \"Can you provide more information about how the MVC components are split into separate files?\"\\n        }\\n    }\\n}',\n",
       " \"The instructions outline a structured approach for creating a functional codebase in Python, focusing on detailed architecture and proper file organization. Here's the summary:\\n\\n1. **Core Components**: Identify and name core classes, functions, and methods, providing brief explanations for their purposes.\\n\\n2. **File Organization**: Start with the entry point file and proceed to import files, ensuring all code is fully implemented and compatible.\\n\\n3. **Markdown Formatting**: Format all code in markdown code blocks, following specific token replacement for filenames, language, and code.\\n\\n4. **Best Practices**: Adhere to language and framework best practices in file naming conventions, including necessary imports and type definitions.\\n\\n5. **Dependency Management**: For Python, include a `requirements.txt` file, denoting module dependencies.\\n\\n6. **Code Completeness**: Ensure that all architectural components are represented in the code and include descriptive comments, especially for complex logic.\\n\\n7. **Test Framework**: Utilize `pytest` along with `dataclasses` for Python projects.\\n\\nThis approach will lead to a well-structured, maintainable, and fully functional codebase while also emphasizing clarity and adherence to programming standards.\",\n",
       " 'The text outlines a set of instructions for creating a functional codebase. The process involves:\\n\\n1. Defining core classes, functions, and methods with brief descriptions of their purposes.\\n2. Producing the complete code for each file, formatted in markdown, with specific naming conventions for both files and code blocks.\\n3. Starting with an entry point file and progressively including imported files, ensuring compatibility and adherence to best practices.\\n4. Including necessary dependency definitions like `requirements.txt` for Python or `package.json` for NodeJS.\\n5. Emphasizing thoroughness in coding, including all imports and types, adding comments for complex logic, and verifying that all architecture components are present.\\n\\nAdditionally, the assistant makes assumptions regarding the model, view, and controller structure for a game’s implementation. The user emphasizes the importance of following the outlined steps closely.',\n",
       " 'The author identifies common limitations encountered in building agents centered around large language models (LLMs) after reviewing key concepts and demonstrations.',\n",
       " 'The text discusses the limitations of using large language models (LLMs) in autonomous agents due to finite context length, which restricts their ability to include historical information or adapt plans over time. It highlights challenges in long-term planning and task decomposition, noting that LLMs struggle to adjust plans when errors occur. Additionally, the reliability of the natural language interface used between LLMs and external components is questioned because of formatting errors and unpredictable behavior. The cited work by Lilian Weng outlines these issues in the context of LLM-powered agents.',\n",
       " 'The article \"LLM-powered Autonomous Agents\" by Lilian Weng, published in June 2023, discusses the development and capabilities of autonomous agents powered by large language models (LLMs). It references several notable studies on prompting techniques and problem-solving approaches that enhance the reasoning abilities of LLMs. These include frameworks like \"Chain of Thought\" and \"Tree of Thoughts,\" as well as tools for optimal planning and reasoning in language models. The article provides insights into the future of LLMs in dynamic tasks, self-reflection, and tool use, supported by a list of related academic references and resources.',\n",
       " 'The text indicates that the content is powered by Hugo and PaperMod.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_summaries(summaries:list[str]) -> str:\n",
    "    client = OpenAI()\n",
    "    combined = \"\\n\".join(summaries)\n",
    "    summary = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Produce a final, reduced, and concise summary of the following list of summaries.\"},\n",
    "            {\"role\": \"user\", \"content\": combined},\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The article \"LLM Powered Autonomous Agents\" by Lilian Weng discusses the development of autonomous agents driven by large language models (LLMs), outlining key components such as planning, memory, and tool use. It emphasizes task decomposition techniques like Chain of Thought and introduces methods for self-reflection, including ReAct and Reflexion, to enhance decision-making. Algorithms like Chain of Hindsight and Algorithm Distillation improve model performance, while memory types (sensory, short-term, long-term) and efficient retrieval methods (e.g., MIPS) are explored.\\n\\nThe article highlights MRKL, a neuro-symbolic architecture, and frameworks like TALM and Toolformer to enhance LLM capabilities through external tools. The API-Bank is introduced to evaluate LLM performance in task execution. Additionally, developments in anticancer drug discovery and simulative Generative Agents showcase complex behaviors. However, limitations of LLMs, such as context length constraints and reliability issues, are noted. Overall, the article presents both the potential and challenges of LLM-powered autonomous agents, advocating for careful tool utilization and expert validation in applications.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_summaries(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
