{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field, TypeAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query(BaseModel):\n",
    "    \"\"\"Input format to query the my_function tool\"\"\"\n",
    "    input_value: float = Field(..., description=\"The input value to the function\")\n",
    "\n",
    "def my_function(query:Query) -> float:\n",
    "    return query.input_value**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Input format to query the my_function tool',\n",
       " 'properties': {'input_value': {'description': 'The input value to the function',\n",
       "   'title': 'Input Value',\n",
       "   'type': 'number'}},\n",
       " 'required': ['input_value'],\n",
       " 'title': 'Query',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_function.__annotations__['query'].model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class LLMWithTools:\n",
    "    def __init__(self, tools:list[Callable]):\n",
    "        self.client = OpenAI()\n",
    "        self.tools = []\n",
    "        self.tool_names = {t.__name__:t for t in tools}\n",
    "        for tool in tools:\n",
    "            self.tools.append(\n",
    "                {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tool.__name__,\n",
    "                        \"description\": tool.__doc__,\n",
    "                        \"parameters\": {\"additionalProperties\": False, **tool.__annotations__['query'].model_json_schema()},\n",
    "                        },\n",
    "                    \"strict\": True\n",
    "                }\n",
    "            )\n",
    "\n",
    "    def invoke(self, prompt:str) -> str:\n",
    "        state = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "        def _client_call():\n",
    "            return self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=state,\n",
    "                tools=self.tools\n",
    "            )\n",
    "        \n",
    "        response = _client_call()\n",
    "\n",
    "        if response.choices[0].message.tool_calls is not None and len(response.choices[0].message.tool_calls) > 0:\n",
    "            state.append(response.choices[0].message)\n",
    "            while response.choices[0].message.tool_calls is not None and len(response.choices[0].message.tool_calls) > 0:\n",
    "                for tool_call in response.choices[0].message.tool_calls:\n",
    "                    tool = self.tool_names[tool_call.function.name]\n",
    "                    query = TypeAdapter(tool.__annotations__['query']).validate_json(tool_call.function.arguments)\n",
    "                    out = tool(query)\n",
    "                    state.append({\n",
    "                        \"role\": \"tool\",\n",
    "                          \"content\": f'{out}',\n",
    "                          \"tool_call_id\": tool_call.id,\n",
    "                          })\n",
    "                response = _client_call()\n",
    "\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLMWithTools([my_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"What is the value of my_function(3)?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The value of `my_function(3)` is 9.0.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
